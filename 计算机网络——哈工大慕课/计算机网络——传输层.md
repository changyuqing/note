# 计算机网络——传输层

## 1. 传输层概述

传输层协议为运行在不同Host上的进程提供了一种逻辑通信机制，此层的消息会被处理或解包成一个个的`Segment`，同时传输层为应用层提供了两种协议`TCP`与`UDP`

**传输层和网络层：**

网络层提供的是主机之间的逻辑通信机制，传输层提供应用进程之间的逻辑通信机制，位于网络层之上依赖网络层服务

**Internet传输层协议：**

* TCP：拥塞控制，流量控制，连接建立，可靠按序的交付服务
* UDP：不可靠的交付服务
* 两种服务都不保证延迟和带宽
* 运输层协议的最低限度是必须提供一种复用和分解的服务

## 2. 多路复用和多路分用

**多路分用**：传输层根据头部信息将受到的`Segment`交给正确的`socket`，即不同的进程

**多路复用**：从多个`socket`接受数据，为每个数据封装上头部信息，生成`segment`，交给网络层

那么分用时如何工作的呢？

* 每个传输层的数据报都携带源IP地址和目的IP地址
* 每个数据报携带一个传输层的段
* 每个段携带源端口号和目的端口号

多路复用如何工作：

* 传输层协议提取IP地址和端口号信息，将`segment`导向相应的`socket`

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170308/134319388.png)

### 2.1 无连接的多路复用与多路分解

无连接的多路分用UDP，大致过程如下：

1. 利用端口号创建Socket
2. UDP的Socket用二元组标识，目的IP地址与端口 
3. 主机收到UDP段后，检查段中的目的端口号，把UDP段导向绑定在该端口号的Socket 
4. 具有相同二元组标识的报文段将被送到相同的进程

那么，标识中的源端口号有什么作用呢?

源端口号作为“返回地址”的一部分，当主机接受到客户机的消息后，如果需要给客户机发消息响应，则可以从客户机发来的报文段从取值获取客户机的端口

### 2.2 面向连接的多路复用与多路分解

面向连接的多路分用TCP，大致过程如下：

1. 创建TCP的Socket，一个四元组标识，源IP地址和目的IP地址，源端口号和目的端口号
2. 接收端利用所有的四个值将`segment`导向合适的Socket
3. 服务器可能同时支持多个TCP的socket，每个socket都有自己的四元组标识
4. web服务器为每个客户端开不同的socket进程

分解时主机会使用全部4个标识来定向分解到相应的套接字，如果有不同源IP和源端口号的TCP报文段，则会被分解到不同的套接字，只有四个值全部匹配，才会分解到之前创建的套接字中，如果不存在则会新建TCP套接字

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170308/142305620.png)

## 3. 无连接运输：UDP

RFC768定义的UDP只是做了运输层协议能够做的做少的工作，除了复用和分解以及少量的差错检测之外，它几乎没有对IP增加别的东西，实际上UDP编程，基本就是直接和IP打交道。

DNS就是一个使用UDP协议的例子，DNS应用程序进行一次查询时，它够着了一个DNS查询的报文并交给UDP，无须做其他任何工作，UDP为此报文添加首部字段然后将形成的报文段发送给网络层，网络层将这个UDP报文段封装进一个IP数据报中，然后将其发送给一个服务器，等待响应，如果没有收到响应，则会试图给另一个DNS服务器发送

那么，为什么对于有些应用宁愿在UDP上构建应用也不再TCP上构建应用呢？主要原因有以下几点

* **关于何时、发送什么数据使用UDP应用层可以控制的更加精细**——只要应用将数据传递给UDP，UDP就会将数据打包进UDP报文段并立即传递给网路层，而在另一方面，TCP有一个拥塞机制，可能会有延迟，所以对于一些实时性要求较高的应用，会使用UDP
* **无需建立连接**——典型如TCP，在数据传输开始之前，需要进行三次握手，UDP却不需要进行任何准备就可以开始传输数据，因此UDP不会有建立连接的时延，这也是为什么DNS会架构在UDP上的原因，而HTTP架设在TCP之上，是因为网页传输必须要有可靠性，数据不能丢
* **无连接状态**——TCP需要再端系统中维护连接状态，此连接状态包括接受和发送缓存、拥塞控制参数以及序号和确认号的参数，而UDP不需要维护连接，也不会跟踪这些参数
* **分组首部开销小**——每个TCP报文都有20字节的首部开销，而UDP仅有8个字节的开销（其中源端口和目的短端口占四个字节）

对于UDP传输的缺点，数据传输不可靠容易丢失，但是可以将可靠性构建在应用中——建立一些确认以及重传机制

### 3.1 UDP报文结构

一共8个字节，源和目的端口号占用四个字节，长度和检验和占四个字节

* 长度：指示了UDP报文段中的字节数（首部信息+数据）
* 检验和：接收方利用这个来检验数据是否出了差错

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170308/150509493.png)

**UDP检验和：**

发送方的UDP对报文段中的所有的16比特字的和进行反码运算，求和时遇到任何溢出都被回卷，得到的结果被放在检验和字段，在接收方，就会把全部的4个16比特字加在一起，如果没有差错，那么结果就是1111111111111111，否则只要有一位是0，那么传输就有问题

回卷：首部溢出的1加到最低位，（1）0100101011000001，回卷就是0100101011000001+1=0100101011000010

### 3.2 可靠数据传输原理

可靠数据传输`reliable data transfer`要求三点：数据不错，数据不丢，数据分组不乱

基本结构：

* rdt_send()：上层调用接口，将数据发送给接收方
* udt_send()：被rdt调用，用来在不可靠的信道上向接收方发送数据
* udt_rcv()：被rdt调用，用来从不可靠的信道上接受数据
* deliver_data()：被rdt调用，向上层应用递交数据

一般来说，底层的信道的数据传输不可靠，可能数据丢失，受损，我们需要有一种协议来保证所有的数据都完整正确的到达目的地。

**具有比特差错信道的可靠数据传输 rdt 2.0**

第一点要解决的就是，如果数据受损，这个协议的控制机制能够要求发送方重传受损的数据包：

* **差错检测：**接收方使用检验和的形式来检测何时出现了比特差错
* **接收方反馈：**正确接收到数据反馈ACK，否则返回NAK
* **重传：**接收方收到有差错的分组时，发送方重传该分组

下图的发送方和接收方表示了`rst 2.0`的有限状态自动机`FSM`，使用了差错检测，肯定否定确认、重传等机制，下文中所有的自动机横线上表示事件，下面表示事件对应的动作

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170310/110651241.png)

对于发送方，一共两个状态，左边的是等待上层的调用来发送数据，给数据进行一些检验和和包装处理，然后转换到下一个状态——等待接受方的回应消息，这个状态下分两种情况：

1. 如果接收方发回的消息是NAK，则重传数据
2. 如果接受方发回的消息是ACK，则切换到发送新数据的状态

这个协议看起来似乎可以运行了，然而实际上有两个致命的缺陷

> (1) 当发送方处理等待ACK或者NAK回应的状态时，它不能发送任何新数据，处于停等状态
>
> (2) 如果发送方的数据在信道上发生丢包，则接收方一直处理等待接受消息的状态，从而发送方也因为没有回应一直等待
>
> (3) 回应的消息ACK或者NAK也可能受损或者丢失，这样会导致发送方无法识别回应消息而一直处理等待状态

我们先忽略第一个缺陷，因为这是发送速率优化的问题，而后两个问题会直接导致数据传输不可靠，为了解决后两个缺陷，可以有这样的解决办法：

* 对于所有含糊不清，也就是回应消息受损的情况，直接重传当前的数据
* 对于数据丢包，或者回应消息丢包的情况，我们设置一个定时器，如果这个时间段没有收到任何的回应消息，重传当前数据

这样我们就可以完美的解决丢包的问题，不过重传又带来了新的问题，重传给信道带来了数据分组冗余，因为接收方不知道这次的数据是新的数据还是一次重传！有可能接收方之前接受了正确的数据，只是回应消息丢包丢了，却会触发发送方重传。

为了解决重传带来得问题，几乎所有的数据传输的协议包括TCP都使用了一个简单的方法：给数据分组标上编号，添加一个新字段，让发送方对数据进行分组，将序号放在该字段，于是接收方只要检查序号是否和上次一样就能知道是新数据还是重传，而且我们只需要一个bit位就能识别，0或者1

**具有比特差错的丢包信道的可靠数据传输： rdt 3.0**

针对上面的缺陷，rdt 3.0提出了很好的解决方案，使用了检验和，肯定否认确定，重传，定时器，编号等方法

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170310/132350806.png)

对于发送者来说，一共有四个状态，等待0序号数据的调用、等待0数据的回应消息以及等待1序号数据的调用、等待1序号数据的回应消息，这几个状态之间的转换条件在图中已经说的很详细了，总之序号与回应消息要对应，超时就重发

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170310/135120769.png)

rdt 3.0 receiver

对于接收和来说，就两个状态，等待0序号或者1序号的数据，当数据受损或者接收数据序号出错，就回应ACK+序号，发送方发现序号不对就会重传。

下面这张图分别是正常工作，丢包，丢失回应消息以及超时的情况，结合这个图就能很好的理解rdt 3.0的工作机制了

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170311/133714144.png)

### 3.3 流水线可靠数据传输协议

对于rdt 3.0来说，我们已经解决了数据传输的可靠性问题，但是之前提出的第一个缺陷却没有得到很好的解决，就是这个协议本质上还是一个停等协议，发出一个数据后必须等待接收方的回应才能进行新数据的发送，这样的话信道的利用率是相当低的，低到万分之2.7，也就是说如果一个1000字节的包发送总共用时30.008ms，那么其中等待的时间则是30ms，有效的吞吐量仅为267kbps，即使有1Gbps的链路可以使用。

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170311/134458600.png)

为了增加传输的效率，我们需要对这种协议加入流水线技术：允许发送方发送多个分组而无需等待确认，但同时也带来如下影响：

* 必须增加序号的范围，并且唯一，用来确认没有确定的分组数据
* 协议的发送方和接收方两端需要缓存多个分组，比如发送方至少要能缓存那些发送但是没有确认的分组

解决流水线的差错恢复由两种基本方法：回退N步和选择重传

**回退N步（Go-Back-N），又叫滑动窗口协议：**

* 流水线中未确认的分组数不能超过某个最大允许数N，即窗口长度为N
* base：已经发送出去但是还没收到ACK的最早的分组
* nextseqnum：下一个等待发送的分组
* 所以在base之前的分组全部已经确认，[base, nextseqnum-1]的分组等待确认，[nextseqnum, base+N-1]的分组等待发送，不在这个返回的分组不允许发送

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170311/135057103.png)

GBN发送方必须响应三种类型的时间：

* 上层的调用，当上层调用rdt_send()时，发送方首先要检查窗口是否满了，即这个分组序号是否在[base,base+N-1]的范围内
* 收到一个ACK，直接将窗口base的值设为ACK的值+1，因为GBN协议接收方是累计确认的
* 超时事件，此时会将窗口内所有已发送但是还没得到确认的分组重传

对于接受者来说，动作很简单，如果一个序号为n的分组被正确接收到，并且上一次接收的分组是n-1，也就是接收必须是按顺序接收，这样才会返回一个含有ACK以及下一个期待接收的分组序号。在其他所有情况下，接收方丢弃该分组，并为最近按序接收的分组重新发送ACK

下图给出了一个基于ACK，无NAK的GBN协议的发送和接受方的FSM描述：

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170311/140810706.png)

好了，现在我们的协议已经可以支持流水线传输了，可以总结下GBN协议的特点：

* 发送方维护一个窗口，维护一个统一的定时器，一旦超时就会重传所以没有确认的报文段
* 接收方采用累积确认，乱序到达的报文段直接丢弃

但是我们同时也会发现，这种GBN滚动窗口协议有一个显而易见的缺陷，尤其当窗口的长度和带宽时延积很大的时候

> 一旦有一个分组出了差错，就会导致大量的分组的重传，显而易见，其实有很多分组不需要重传

**选择重传(Selective-repeat)：**

顾明思义，选择重传协议通过让发送方重传那些它怀疑在接收方出错的分组，去避免不必要的重传，为了做到这点，选择重传做的主要工作就是让接受方也有一个窗口，并要求可以缓存那些没有按序交付的分组，而对于发送方，必须给每个分组设置一个计时器，一旦有分组超时就重发，而之前是统一的一个计时器，跟着base的序号在计时

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170311/142942930.png)

对于发送方，它的事件和对应的动作如下：

* **从上层接受到数据**，检查下一个可以用于该分组的序号，如果这个序号在窗口内，则发送，否则要么缓存，要么返回给上层以便以后发送
* **超时**。对每个分组都设置定时器，一旦出现超时，该分组就重发
* **收到ACK**。如果ACK信息中包含的分组序号在窗口内，则把该分组标记为已确认，如果分组的序号等于send_base，则send_base向前移动，直到具有最小序号的待确认分组处，窗口移动之后，有之前缓存的分组进入了窗口中，则发送这些分组

对于接收者来说，它的时间和对应的动作如下：

* **接收到分组数据**，如果该分组的序号在窗口内[rcv_base, rcv_base+N-1]，并且被无损的正确接收，就会返回一个ACK消息。同时，如果这个分组之前没有收到过，则缓存该分组，如果恰好这个分组的序号等于rcv_base，那么则交付该分组给上层
* 序号在[rcv_base - N, rcv_base - 1]内的分组被正确接收到，在此情况下，必须产生一个ACK，即使之前已经确认过
* 其他情况则忽略该分组，不做任何动作

> 对于接收方的第二点要格外注意，对已经接受过的分组必须发送ACK，因为对ACK这个消息来说，它可能丢失，那么发送方就会超时重传，但实际接受方已经收到了并且窗口已经向前滑动了，如果对于这个分组不回应ACK，则发送方的窗口永远的停留在那里，不会滑动。

到了这里就可以总结一下SR的特点：

* 相比GBN协议，SR会对每个计时器维护一个定时器，超时就重发
* 接受方和发送方都要维护窗口，会缓存报文段，不是累积确认

看一个图片的例子，来更加清晰的了解选择重传的机制

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170311/151659947.png)

从上图中可以看到，当0,1,2,3分组发出去后，窗口满了就会停止发送，等到基序号的分组被确认后才会向前滑动窗口，此时就有新的分组待发送。当出现分组丢失，如2，超时重发，而对于接收方，只有当受到基序号的分组才会滑动窗口，向上层递交数据。

对于SR协议，我们还有一个需要去考虑的问题，就是序号范围以及窗口的大小如何设置，才能恰到好处不出问题，为了得到正确的答案，先举两个反例：

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170311/154035290.png)

在第一个例子中，我们可以看到，即使发送方在规定时间内由于没有收到回应的消息而做出了正确的反应，但是接受方却因为认为接受到了正确的分组向前滑动了窗口，导致重传的0序号的分组被认为是一个新的分组，数据出错，导致这一出错的原因就是：分组的序号范围对于窗口长度来说太小了。

在第二例子中，接受方没有办法区别pkt0到底是一个新的分组还是重传。

显然，窗口的长度和序号的范围必须合适，SR协议才能正常的工作，归根结底就是要让接收方能够通过序号知道这是重传还是新数据，那怎样才能算合适？

> 分组序号的范围必须是窗口长度的两倍，这样就能避免前后窗口序号的重复而导致的迷惑

## 4. 面向连接的运输：TCP

对于TCP来说，它有以下特点：

* 点对点
* 可靠的、按序的字节流
* 流水线机制：TCP拥塞控制和流量控制机制设置窗口尺寸
* 发送方接受方缓存
* 全双工
* 面向连接：通信双方在发送数据之前必须建立连接
* 流量控制机制

### 4.1 TCP报文结构

和UDP一样，TCP也含有源端口和目的端口号，用于多路分解和多路复用，另外TCP报文段还含有以下字段：

* 32比特的序号字段和32比特的确定字段，用来实现可靠数据传输服务，序号和确认号都是基于字节流来建立的
* 16比特的接受窗口字段，用于流量控制
* 4比特的首部长度字段，该字段指示了以32比特为字的TCP首部长度，TCP一般是20字节，但是可变
* 可选和变长的选项字段，该字段用于接受发送双方协商最大报文长度（MMS）
* 6个比特的标志字段，ACK用于确认，SYN用于建立连接，FIN用于断开连接，PSH被标志后说明该数据应该被交给上层

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170316/091136807.png)

**报文的序号基于字节流**：一个报文段的序号就是它本身第一个字节的序号，例如下图中的第一个报文段的序号就是0，第二个就是1000

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170316/164413577.png)



### 4.2 RTT估计与超时

TCP是单一计时器，与SR不同，而这个计时器的设置是根据网络环境动态设置的，每一个发送的报文段到被确定，都会有自己的SampleRTT，所以计时器会把最新的这个RTT取入作平均。

> EstimatedRTT = (1- a) * EstimatedRTT + a * SampleRTT

其中a参考值是0.125，所以`EstimatedRTT `是`SampleRTT`的一个加权平均值

除了估算RTT之外，估算RTT的变化也是很有价值的，即DevRTT

> DevRTT = (1 - b) * DevRTT + b  * | SampleRTT - EstimatedRTT |

所以如果RTT的波动性很大，那么DevRTT的值就很大，其中b的参考值是0.25

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170316/125811262.png)

**设置超时时间**

从上面我们已经得到了`EstimatedRTT`和`DevRTT`的值，所以超时时间的计算可以这样综合：

> TimeoutInterval = EstimatedRTT + 4 * DevRTT

`TimeoutInterval`推荐的初始值是1秒，当出现超时就加倍，但是无论如何，一旦受到报文ACK更新`EstimatedRTT `后，就会使用上述公式计算

### 4.3 TCP发送方事件

发送方会处理三个事件，分别对应不同的情况：

* **从应用层受到数据**：将数据封装进报文段中，并把该报文段交给IP，序列号是`segment`第一个字节的编号，开启计时器，设置超时时间
* **超时**： 重传引起超时的`segment`，并且将超时的时间加倍，例如之前超时时间设置为0.75秒，超时后直接设置为1.5s，只有当定时器在另外两个事件（从上层收到数据或者接收到ACK）时，才会使用最近的`EstimatedRTT `和`DevRTT`来推算得到超时时间
* **来自接收方的ACK确认：**当事件发生时，TCP将ACK的值和变量`sendBase`进行比较，`sendBase`是最早未被确认的字节序号，如果ACK的值大于`sendBase`，则将其设置为ACK的序号值，因为接收方采用的是累计确认，所以之前的序号肯定被接受到了，否则接收方不会发送这个ACK

用代码描述TCP发送方的事件，则如下：

```c
/* Assume sender is not constrained by TCP flow or congestion control, that data from above is less
than MSS in size, and that data transfer is in one direction only. */
NextSeqNum=InitialSeqNumber
SendBase=InitialSeqNumber
loop (forever) {
    switch(event)
        event: data received from application above
            create TCP segment with sequence number NextSeqNum
            if (timer currently not running)
            	start timer
            pass segment to IP
            NextSeqNum=NextSeqNum+length(data)
            break;
        event: timer timeout
            retransmit not-yet-acknowledged segment with
            	smallest sequence number
            start timer
            break;
        event: ACK received, with ACK field value of y
            if (y > SendBase) {
            	SendBase=y 
                if (there are currently any not-yet-acknowledged segments)
                    start timer
            }
            break;
} /* end of loop forever */
```

对于发送方的重传以及`sendBase`的推进下面几个例子能够很好的帮助理解：

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170316/170049583.png)

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170316/170203063.png)

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170316/170215216.png)

**快速重传**

你可能注意到，当TCP发送方检测到超时时，会直接将定时器加倍，这样的话会导致代价很大，重发要等很久，然而实际中发送方经常一个接一个大量的发送报文段，如果其中一个报文段丢失，就等上一个定时器的时间之后再重传，这样效率是很低的。

于是TCP针对这个情况有一个快速重传的机制：当发送方收到对相同数据的3个冗余ACK，说明有一个包丢失了，那么此时不需要等到超时，而是直接启动重传。举例见下图：

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170316/172204922.png)

发送方收到3个冗余ACK后就直接重传，而不是等到超时

```c
event: ACK received, with ACK field value of y
    if (y > SendBase) {
        SendBase=y
        if (there are currently any not yet
                 acknowledged segments)
        	start timer
    }
    else { 
      /* a duplicate ACK for already ACKed
    segment */
    	increment number of duplicate ACKs
        received for y
        if (number of duplicate ACKS received
        for y==3)
        	/* TCP fast retransmit */
        	resend segment with sequence number y
    }
    break;
```

### 4.4 TCP接受方事件

TCP的接收方采用累积确认的方式，同时，RFC没有规定对于那些失序到达的报文段如果处理，可以选择丢弃，也可以选择缓存：

* **期望序号的报文段按序到达且无ACK等待：**这种情况下，收到期望并且按序的报文段，接收方不会立刻发送ACK，会等待500ms，如果这500ms内下一个期望的ACK没有到达，则发送当前ACK
* **期望序号的报文段按序到达且有ACK等待：**这种情况的ACK叫做累积ACK，用来确定连续两个报文段的确定，这时会发送一个最新的ACK，原来的就不必发送了
* **比期望大的序号报文段到达：**立即发送冗余ACK（即期望的ACK），告诉发送端我现在期望的序号。至于这个乱序的报文段如何处理，RFC没有明确规定，可以选择丢弃，也可以选择缓存

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170316/170319690.png)

### 4.5 流量控制

之所以要流量控制，是因为发送方和接受方的速率不匹配，发送方太快，接收方读取慢导致接收缓存满了，如果发送方依旧快速发送数据，那么这些数据将全部丢失，所以TCP提供了流量控制机制，当遇到这种情况时，将使发送方停止发送数据

TCP协议通过让发送方维护一个接收窗口的变量来提供流量控制，因为TCP是全双工的，所以双方都是发送者，都会维护一个接收窗口

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170316/222045591.png)

图中RecBuffer表示缓存的总空间大小，rwnd表示接收窗口，也就是接收方空闲可用的空间，对于接收方，需要计算出rwnd的值，计算方法如下：

* LastByteRead：应用程序从缓存中读出的数据流的最后一个字节的编号
* LastByteRcvd：从网络中到达接收方的报文段，并且放入接收缓存的最后一个报文段的字节编号

所以rwnd的值，也就是空闲的缓存空间计算公式如下：

> *rwnd = RcvBuffer - [ LastByteRcvd - LastByteRead ]*

那么，连接如何使用变量rwnd提供流量控制的呢，对于主机B，通过把rwnd值放入报文段中通知主机A自己还有多少可用缓存空间，rwnd的初始值为RecBuffer，主机A就得保证：

> *LastByteSend - LastByteAcked <= rwnd*

这样就能保存接收方不会溢出数据导致丢包了，还有一个问题，当流量控制后，如果重新恢复发送呢？为了解决这个问题，TCP规范中要求：当主机B的接受窗口为0之后，主机A继续发送只有一个字节数据的报文段，接收方识别后就会开始清空缓存，发回一个rwnd值不为0的确认报文，那么主机A就能恢复发送了

### 4.6 连接管理

这一小节，来讨论TCP连接的建立和拆除，首先建立连接时，会有一个俗称三次握手的步骤，而拆除连接就是四次挥手

**三次握手建立连接：**

* 第一步：客户端的TCP首先向服务器端的TCP发送一个特殊的TCP报文，该报文的SYN标志位置为1，另外客户端会随机的选择一个初始序号（client_isn）,放入序号字段中
* 第二步，服务器接受到SYN为1的报文段，会分配内存和变量，并发回一个SYN为1，确认号字段为client_isn+1的报文段，同时该报文段的序号会初始化为`server_isn`，表示服务器允许连接，所以有时候该报文也被称为SYNACK报文段
* 第三步，收到`SYNACK`报文段之后，客户端也会分配缓存和变量，同时发回一个最终确认的报文段，因为连接已经建立，所以SYN被置为0，同时确认号设置为`server_isn+1`

一旦完成这三个步骤，双方就可以开始发送数据了，图示如下：

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170316/224655850.png)

**四次挥手拆除连接：**

这里就不用详细解释了，一张图说明一切：

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170316/224936660.png)

值得注意的是，连接关闭的发起方会有一个超时等待时间才会关闭连接，这个时间是30s，因为最后的ACK可能丢失，这个时间用来重发最后的ACK报文。

下图是TCP客户端的典型有限状态机：

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170316/225212918.png)

TCP服务器端的有限状态机：

![mark](http://ogzrgstml.bkt.clouddn.com/blog/20170316/225314071.png)

### 4.7 拥塞控制

老惯例，先说为什么要拥塞控制，和流量控制不同的是，虽然都是限制发送方的数据发送，但是本质原因是不同的，流量控制是因为接收方缓存满了，而拥塞控制是因为传输过程中网络环境变差，从而降低发送方的速率来缓解链路上的拥堵。

那么，问题来了，第一个问题：一个TCP发送方如何限制它向其他链接发送流量的速率呢？第二个问题：一个TCP发送方如何感知它到目的地的网络链路上的环境存在拥塞呢？第三个问题：如果链路有拥堵了，采用何种策略去改变发送速率？

首先回答第一个问题：TCP发送方拥塞控制机制跟踪一个额外的变量，即拥塞窗口`cwnd`，由它来限制发送速率

第二个问题：拥塞很简单，只要链路上的路由器缓存溢出了，那么一定会丢包，一旦丢包，就会出现超时或者冗余ACK，出现这两种情况就说明链路出现拥塞

第三个问题：既然我们可以通过`cwnd`的值来控制发送速率，那就给`cwnd`的值的改变设置条件和约束，详细的内容我们后面来解释

接下来展示拥塞控制的细节，TCP拥塞控制的算法包含三个主要部分：慢启动，拥塞避免以及快速恢复

**慢启动：**

当一个TCP连接开始时，cwnd的值通常初始置为一个MSS的较小值，所以初始的发送速率就是MSS/RTT，如果MSS是500字节而RTT是200ms，那么发送速率大概是20kb/s，对于可用带宽来说，这个速率太低了，所以后续`cwnd`的值不断翻倍乘以2，使发送速率成指数增长。

那么什么时候结束这种野蛮的指数增长呢？发送方还会设置一个慢启动的阈值`ssthresh`，当`cwnd`的值是`ssthresh`时，停止指数增长，改为为线性增长，`cwnd`不断的加一个MSS，这个时候会结束慢启动，转入拥塞避免状态